# BRO - Multimodal AI Assistant

**Think â†’ Decide â†’ Remember â†’ See â†’ Act â†’ Automate**

A fully local, offline-capable AI assistant inspired by Iron Man's J.A.R.V.I.S.

## âœ¨ Features

| Capability | Description | Status |
|:-----------|:------------|:------:|
| ğŸ§  **Cognitive Loop** | Think before acting | âœ… |
| ğŸ’¾ **Long-Term Memory** | Remembers facts across sessions | âœ… |
| ğŸ”€ **Smart Routing** | Auto-selects specialist models | âœ… |
| ğŸŒ **Hybrid Mode** | Gemini (cloud) / Ollama (local) | âœ… |
| ğŸ‘ï¸ **Vision** | See and understand your screen | âœ… NEW |
| â° **Wake Word** | "Hey BRO" hands-free activation | âœ… NEW |
| ğŸŒ **Web Automation** | Control browser, fill forms, click | âœ… NEW |
| ğŸ“„ **File Conversion** | Convert images, PDFs, docs | âœ… NEW |
| ğŸ™ï¸ **Voice I/O** | Talk to BRO, hear responses | âœ… |

## ğŸš€ Quick Start

```powershell
# 1. Clone and enter directory
cd BRO

# 2. Install dependencies
pip install -r requirements.txt

# 3. Setup AI (choose one or both)
# ONLINE: Add GEMINI_API_KEY to .env
# OFFLINE: ollama pull llama3.2

# 4. (Optional) Install vision support
ollama pull llava

# 5. (Optional) Install web automation
playwright install chromium

# 6. Run BRO
python main.py
```

## ğŸ® Startup Modes

```powershell
python main.py              # Standard mode (type or say 'mic')
python main.py --voice      # Voice-first mode
python main.py --wake-word  # Always-on "Hey BRO" mode
```

## ğŸ’¬ Example Commands

### Desktop Control
- "Open Chrome"
- "Close Spotify"
- "Take a screenshot"
- "What processes are running?"

### Vision (requires LLaVA)
- "What's on my screen?"
- "Find the save button"
- "Read the text on screen"
- "Describe this image"

### Web Automation (requires Playwright)
- "Go to google.com and search for Python tutorials"
- "Click the Sign In button"
- "Type my email in the login field"
- "What does this page say?"

### File Conversion
- "Convert this PNG to JPEG"
- "Extract text from document.pdf"
- "Read the slides from presentation.pptx"

### Memory
- "Remember my project is called Alpha"
- "What's my project name?"
- "My favorite color is blue"

## ğŸ“‹ Text Commands

| Command | Action |
|---------|--------|
| `help` | Show available commands |
| `status` | System status (AI, memory, capabilities) |
| `models` | Show specialist model routing |
| `memory` | Show memory stats |
| `forget` | Clear all memories |
| `clear` | Clear conversation history |
| `mic` | Activate voice input |
| `quit` | Exit BRO |

## ğŸ› ï¸ Architecture

```
BRO/
â”œâ”€â”€ main.py              # Entry point & CLI
â”œâ”€â”€ config.py            # All settings
â”œâ”€â”€ requirements.txt     # Dependencies
â”‚
â”œâ”€â”€ llm/                 # AI Brains
â”‚   â”œâ”€â”€ cognitive_brain.py   # Main brain (Gemini + Ollama)
â”‚   â”œâ”€â”€ hybrid_brain.py      # Fallback hybrid
â”‚   â””â”€â”€ model_selector.py    # Smart model routing
â”‚
â”œâ”€â”€ cognitive/           # Thinking Engine
â”‚   â””â”€â”€ engine.py        # Think â†’ Decide loop
â”‚
â”œâ”€â”€ memory/              # Long-term Memory
â”‚   â””â”€â”€ chromadb store   # Vector database
â”‚
â”œâ”€â”€ voice/               # Voice I/O
â”‚   â”œâ”€â”€ tts.py           # Text-to-Speech
â”‚   â”œâ”€â”€ stt.py           # Speech-to-Text
â”‚   â”œâ”€â”€ wake_word.py     # "Hey BRO" detection (NEW)
â”‚   â””â”€â”€ local_tts.py     # Enhanced TTS (NEW)
â”‚
â””â”€â”€ tools/               # Actions
    â”œâ”€â”€ pc_control.py    # Open/close apps, type, keys
    â”œâ”€â”€ file_ops.py      # File operations
    â”œâ”€â”€ browser.py       # Basic web browsing
    â”œâ”€â”€ vision.py        # Screen vision (NEW)
    â”œâ”€â”€ web_automation.py # Playwright browser control (NEW)
    â””â”€â”€ file_convert.py  # File format conversion (NEW)
```

## ğŸ”§ Configuration

Edit `.env` or `config.py`:

```env
# AI
GEMINI_API_KEY=your_key_here
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Vision
VISION_MODEL=llava

# Voice
TTS_RATE=175
TTS_VOLUME=1.0
MIC_DEVICE_INDEX=  # Leave empty for default

# Wake Word
WAKE_WORD_ENABLED=false
```

## ğŸ“¦ Optional Dependencies

| Feature | Install Command | Size |
|---------|-----------------|------|
| Vision | `ollama pull llava` | ~4GB |
| Web Automation | `playwright install chromium` | ~280MB |
| Wake Word | `pip install vosk` | ~50MB model |
| OCR | Install [Tesseract](https://github.com/UB-Mannheim/tesseract/wiki) | ~30MB |

## ğŸ§ª Test Components

```powershell
# Test vision
python -c "from tools.vision import vision_status; print(vision_status())"

# Test TTS
python voice/local_tts.py

# Test wake word
python voice/wake_word.py
```

## ğŸ¯ Cognitive Actions

| Action | Trigger | Example |
|--------|---------|---------|
| ğŸ’¾ REMEMBER | "my name is...", "remember that..." | Saves to memory |
| ğŸ” RECALL | "what's my...", "do you remember..." | Retrieves from memory |
| âš¡ ACT | "open...", "close...", "run..." | Executes system command |
| ğŸ’» CODE | "write code...", "debug..." | Uses coding specialist |
| ğŸ‘ï¸ SEE | "what's on screen...", "find..." | Uses vision model |
| ğŸŒ WEB | "go to...", "search...", "click..." | Controls browser |
| ğŸ“„ CONVERT | "convert...", "extract text..." | File operations |
| ğŸ’¬ CHAT | Everything else | General conversation |

## ğŸ’¡ How It Works

```
You: "Open my project folder"

1. ğŸ¤ STT: Transcribes your voice
2. ğŸ§  THINK: Analyzes intent
3. ğŸ” RECALL: Checks memory for "project"
4. âš¡ DECIDE: Action = open_folder
5. ğŸ–±ï¸ ACT: Opens the folder
6. ğŸ”Š TTS: "Opened your Alpha project folder"
```

## ğŸ”’ Privacy

- All processing happens locally when using Ollama
- Memory stored locally in `BRO_memory/`
- No data sent to cloud (unless using Gemini)
- Vision uses local LLaVA model

## ğŸ“ License

MIT License - Feel free to modify and use!

---

**Made with â¤ï¸ inspired by Iron Man's J.A.R.V.I.S.**
